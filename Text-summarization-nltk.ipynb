{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT SUMMARIZATION USING THE FREQUENCY METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method we find the frequency of all the words in our text data and store the text data and its frequency in a dictionary. After that, we tokenize our text data. The sentences which contain more high frequency words will be kept in our final summary data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Importing Libraries \n",
    " Importing Libraries and downloading necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Text to summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text  = \"\"\"\n",
    "You see the problem with these young children is they do not want to listen now I told Jane\n",
    "to take the trash out but she refused. Now, Ethan and Abby are fighting over a cup of tea. I\n",
    "don't know what to do for them, but probably we shall take them to the daycare, then they\n",
    "can be okay. Also, they will be having exams starting next week. So, they will need to be\n",
    "sleeping early enough so that they can get enough rest for for so that they can perform well\n",
    "in the exam. Other than that, everything at home is okay. How is your trip and the children\n",
    "are expecting some chocolate when you return. So, whatever you do, stock up on chocolate\n",
    "biscuits, sweets, and all these pleasantries that children like they will be waiting by\n",
    "\"\"\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain a list of stop words. Stop words are words that don't add meaning to a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You',\n",
       " 'see',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'with',\n",
       " 'these',\n",
       " 'young',\n",
       " 'children',\n",
       " 'is',\n",
       " 'they',\n",
       " 'do',\n",
       " 'not',\n",
       " 'want',\n",
       " 'to',\n",
       " 'listen',\n",
       " 'now',\n",
       " 'I',\n",
       " 'told',\n",
       " 'Jane',\n",
       " 'to',\n",
       " 'take',\n",
       " 'the',\n",
       " 'trash',\n",
       " 'out',\n",
       " 'but',\n",
       " 'she',\n",
       " 'refused',\n",
       " '.',\n",
       " 'Now',\n",
       " ',',\n",
       " 'Ethan',\n",
       " 'and',\n",
       " 'Abby',\n",
       " 'are',\n",
       " 'fighting',\n",
       " 'over',\n",
       " 'a',\n",
       " 'cup',\n",
       " 'of',\n",
       " 'tea',\n",
       " '.',\n",
       " 'I',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'what',\n",
       " 'to',\n",
       " 'do',\n",
       " 'for',\n",
       " 'them',\n",
       " ',',\n",
       " 'but',\n",
       " 'probably',\n",
       " 'we',\n",
       " 'shall',\n",
       " 'take',\n",
       " 'them',\n",
       " 'to',\n",
       " 'the',\n",
       " 'daycare',\n",
       " ',',\n",
       " 'then',\n",
       " 'they',\n",
       " 'can',\n",
       " 'be',\n",
       " 'okay',\n",
       " '.',\n",
       " 'Also',\n",
       " ',',\n",
       " 'they',\n",
       " 'will',\n",
       " 'be',\n",
       " 'having',\n",
       " 'exams',\n",
       " 'starting',\n",
       " 'next',\n",
       " 'week',\n",
       " '.',\n",
       " 'So',\n",
       " ',',\n",
       " 'they',\n",
       " 'will',\n",
       " 'need',\n",
       " 'to',\n",
       " 'be',\n",
       " 'sleeping',\n",
       " 'early',\n",
       " 'enough',\n",
       " 'so',\n",
       " 'that',\n",
       " 'they',\n",
       " 'can',\n",
       " 'get',\n",
       " 'enough',\n",
       " 'rest',\n",
       " 'for',\n",
       " 'for',\n",
       " 'so',\n",
       " 'that',\n",
       " 'they',\n",
       " 'can',\n",
       " 'perform',\n",
       " 'well',\n",
       " 'in',\n",
       " 'the',\n",
       " 'exam',\n",
       " '.',\n",
       " 'Other',\n",
       " 'than',\n",
       " 'that',\n",
       " ',',\n",
       " 'everything',\n",
       " 'at',\n",
       " 'home',\n",
       " 'is',\n",
       " 'okay',\n",
       " '.',\n",
       " 'How',\n",
       " 'is',\n",
       " 'your',\n",
       " 'trip',\n",
       " 'and',\n",
       " 'the',\n",
       " 'children',\n",
       " 'are',\n",
       " 'expecting',\n",
       " 'some',\n",
       " 'chocolate',\n",
       " 'when',\n",
       " 'you',\n",
       " 'return',\n",
       " '.',\n",
       " 'So',\n",
       " ',',\n",
       " 'whatever',\n",
       " 'you',\n",
       " 'do',\n",
       " ',',\n",
       " 'stock',\n",
       " 'up',\n",
       " 'on',\n",
       " 'chocolate',\n",
       " 'biscuits',\n",
       " ',',\n",
       " 'sweets',\n",
       " ',',\n",
       " 'and',\n",
       " 'all',\n",
       " 'these',\n",
       " 'pleasantries',\n",
       " 'that',\n",
       " 'children',\n",
       " 'like',\n",
       " 'they',\n",
       " 'will',\n",
       " 'be',\n",
       " 'waiting',\n",
       " 'by']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(text)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally punctuation doesnot come come with new line character '\\n so we add that to punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\n\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = punctuation + '\\n'\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Frequency Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word tokenize the entire text. We have to create the dictionary with key as words and value as number of times word is repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'see': 1,\n",
       " 'problem': 1,\n",
       " 'young': 1,\n",
       " 'children': 3,\n",
       " 'want': 1,\n",
       " 'listen': 1,\n",
       " 'told': 1,\n",
       " 'Jane': 1,\n",
       " 'take': 2,\n",
       " 'trash': 1,\n",
       " 'refused': 1,\n",
       " 'Ethan': 1,\n",
       " 'Abby': 1,\n",
       " 'fighting': 1,\n",
       " 'cup': 1,\n",
       " 'tea': 1,\n",
       " \"n't\": 1,\n",
       " 'know': 1,\n",
       " 'probably': 1,\n",
       " 'shall': 1,\n",
       " 'daycare': 1,\n",
       " 'okay': 2,\n",
       " 'Also': 1,\n",
       " 'exams': 1,\n",
       " 'starting': 1,\n",
       " 'next': 1,\n",
       " 'week': 1,\n",
       " 'need': 1,\n",
       " 'sleeping': 1,\n",
       " 'early': 1,\n",
       " 'enough': 2,\n",
       " 'get': 1,\n",
       " 'rest': 1,\n",
       " 'perform': 1,\n",
       " 'well': 1,\n",
       " 'exam': 1,\n",
       " 'everything': 1,\n",
       " 'home': 1,\n",
       " 'trip': 1,\n",
       " 'expecting': 1,\n",
       " 'chocolate': 2,\n",
       " 'return': 1,\n",
       " 'whatever': 1,\n",
       " 'stock': 1,\n",
       " 'biscuits': 1,\n",
       " 'sweets': 1,\n",
       " 'pleasantries': 1,\n",
       " 'like': 1,\n",
       " 'waiting': 1}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies = {}\n",
    "for word in words:\n",
    "    if word.lower() not in stop_words:\n",
    "        if word.lower() not in punctuation:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "\n",
    "word_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize word frequncies\n",
    "Obtain the maximum frequncy from the dictionary and divide all frequencies with the max frequency to obtain normalized frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "max_frequency = max(word_frequencies.values())\n",
    "print(max_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nYou see the problem with these young children is they do not want to listen now I told Jane\\nto take the trash out but she refused.',\n",
       " 'Now, Ethan and Abby are fighting over a cup of tea.',\n",
       " \"I\\ndon't know what to do for them, but probably we shall take them to the daycare, then they\\ncan be okay.\",\n",
       " 'Also, they will be having exams starting next week.',\n",
       " 'So, they will need to be\\nsleeping early enough so that they can get enough rest for for so that they can perform well\\nin the exam.',\n",
       " 'Other than that, everything at home is okay.',\n",
       " 'How is your trip and the children\\nare expecting some chocolate when you return.',\n",
       " 'So, whatever you do, stock up on chocolate\\nbiscuits, sweets, and all these pleasantries that children like they will be waiting by']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted frequencies of the sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted frequency for each sentence is obtained by adding together the frequency occurence of each word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "sentenceValue = dict()\n",
    "\n",
    "for sentence in sentences:\n",
    "    for word, freq in word_frequencies.items():\n",
    "        if word in sentence.lower():\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq\n",
    "   \n",
    "   \n",
    "   \n",
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "    sumValues += sentenceValue[sentence]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = int(sumValues / len(sentenceValue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "You see the problem with these young children is they do not want to listen now I told Jane\n",
      "to take the trash out but she refused. So, they will need to be\n",
      "sleeping early enough so that they can get enough rest for for so that they can perform well\n",
      "in the exam. So, whatever you do, stock up on chocolate\n",
      "biscuits, sweets, and all these pleasantries that children like they will be waiting by\n"
     ]
    }
   ],
   "source": [
    "summary = \"\"\n",
    "for sentence in sentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence]>(1.2*average)):\n",
    "        summary += \" \"+ sentence\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You see the problem with these young children is they do not want to listen now I told Jane\n",
      "to take the trash out but she refused. Now, Ethan and Abby are fighting over a cup of tea. I\n",
      "don't know what to do for them, but probably we shall take them to the daycare, then they\n",
      "can be okay. Also, they will be having exams starting next week. So, they will need to be\n",
      "sleeping early enough so that they can get enough rest for for so that they can perform well\n",
      "in the exam. Other than that, everything at home is okay. How is your trip and the children\n",
      "are expecting some chocolate when you return. So, whatever you do, stock up on chocolate\n",
      "biscuits, sweets, and all these pleasantries that children like they will be waiting by\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Input text - to summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text  = \"\"\"\n",
    "You see the problem with these young children is they do not want to listen now I told Jane\n",
    "to take the trash out but she refused. Now, Ethan and Abby are fighting over a cup of tea. I\n",
    "don't know what to do for them, but probably we shall take them to the daycare, then they\n",
    "can be okay. Also, they will be having exams starting next week. So, they will need to be\n",
    "sleeping early enough so that they can get enough rest for for so that they can perform well\n",
    "in the exam. Other than that, everything at home is okay. How is your trip and the children\n",
    "are expecting some chocolate when you return. So, whatever you do, stock up on chocolate\n",
    "biscuits, sweets, and all these pleasantries that children like they will be waiting by\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Creating a frequency table to keep the\n",
    "# score of each word\n",
    "\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "\tword = word.lower()\n",
    "\tif word in stopWords:\n",
    "\t\tcontinue\n",
    "\tif word in freqTable:\n",
    "\t\tfreqTable[word] += 1\n",
    "\telse:\n",
    "\t\tfreqTable[word] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dictionary to keep the score of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "sentenceValue = dict()\n",
    "\n",
    "for sentence in sentences:\n",
    "\tfor word, freq in freqTable.items():\n",
    "\t\tif word in sentence.lower():\n",
    "\t\t\tif sentence in sentenceValue:\n",
    "\t\t\t\tsentenceValue[sentence] += freq\n",
    "\t\t\telse:\n",
    "\t\t\t\tsentenceValue[sentence] = freq\n",
    "\n",
    "\n",
    "\n",
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "\tsumValues += sentenceValue[sentence]\n",
    "\n",
    "# Average value of a sentence from the original text\n",
    "\n",
    "average = int(sumValues / len(sentenceValue))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing sentences into our summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " So, they will need to be\n",
      "sleeping early enough so that they can get enough rest for for so that they can perform well\n",
      "in the exam.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "summary = ''\n",
    "for sentence in sentences:\n",
    "\tif (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
    "\t\tsummary += \" \" + sentence\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a468afd87b214c8448be3cc243daf44d9fe1315ae30f84a6ae7ec98f1fe5184"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
